{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32c40e70-5d4c-484b-ae0e-4fc0f122ee1a",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Cleaning and Preparing Reviews Data</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c7eb7c-85c1-4b5f-a06e-921b7f5bc21d",
   "metadata": {},
   "source": [
    "*******************************************************************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f04db30-cb1d-4ce2-a425-629c4e782a5c",
   "metadata": {},
   "source": [
    "<h2>1. Introduction</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22f778f-59b4-4107-82a1-71ff7db43be0",
   "metadata": {},
   "source": [
    "### Data Cleaning Overview\n",
    "\n",
    "In this project, reviews were collected using the `fetch_reviews.py` script, which extracted reviews for each location listed in the `places_processed.csv` file. Due to limitations in the Google API, only 5 reviews could be extracted per place. The collected data underwent several cleaning steps to prepare it for further analysis. These included:\n",
    "\n",
    "- **Handling missing values**: Rows with missing ratings or reviews were removed.\n",
    "- **Removing duplicates**: Duplicate reviews based on the Review ID were removed.\n",
    "- **Text Length and Word Count Analysis**: Calculated the length (in characters) and word count for each review, adding these as new columns in the dataset.\n",
    "- **Data reordering**: Columns were reordered to ensure clarity and consistency in the dataset.\n",
    "\n",
    "These steps helped ensure that the review data is clean, accurate, and ready for analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62e1ead-0fcf-4098-8dac-afe3829b954b",
   "metadata": {},
   "source": [
    "<h2>2. Initialization</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a63ce46-5c6f-4c83-865c-74b12cea2a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Imports\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ef5e97-4acd-4e3b-9936-9cd937560479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configures Pandas display settings: shows all columns in DataFrames and suppresses chained assignment warnings  \n",
    "pd.set_option(\"display.max_columns\", None)  \n",
    "pd.options.mode.chained_assignment = None  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c432bd-bd28-4b65-a22f-1c2cb8716907",
   "metadata": {},
   "source": [
    "<h2>3. Load the Dataset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c3d2df-26ee-455c-bddc-fd16314f9155",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.path.abspath(os.path.join(\"..\", \"data\", \"raw\", \"reviews_raw.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d119ef5-2e31-4efc-9307-34c5c6f7d1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_csv(PATH, sep=\";\", header=0, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53619977-0c12-4805-a6f8-280dca305803",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cf2a42-e4d2-4505-aa59-9c6e4187000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce0a2fe-072e-4c53-b0b8-d56f3fbd9c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b53bf1c-e090-4bbf-bf35-b396d178bf46",
   "metadata": {},
   "source": [
    "<h2>4. Data Cleaning</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1071d31-3f83-4bbf-8203-148e9e238e8a",
   "metadata": {},
   "source": [
    "<h3>4.1 Convert Columns Data Types</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336633b6-28fb-4e86-8ba6-3d0ee38558a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_types(df):\n",
    "    \"\"\"\n",
    "    Convert columns of the given DataFrame to specified data types.\n",
    "\n",
    "    This function takes a DataFrame and converts its columns to specific data types. The data types \n",
    "    for columns are defined in the col_dict dictionary. Additionally, it ensures that the 'Text' column \n",
    "    is of string type, with NaN values replaced by an empty string. The 'Date' column is also converted \n",
    "    to datetime format.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The input DataFrame containing the review data.\n",
    "\n",
    "    Returns:\n",
    "    pandas.DataFrame: The DataFrame with the columns converted to specified data types.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Dictionary defining the desired data types for each column\n",
    "    col_dict = {\n",
    "        'Place ID': 'str',     # 'Place ID' should be a string\n",
    "        'Place Name': 'str',   # 'Place Name' should be a string\n",
    "        'Review ID': 'str',    # 'Review ID' should be a string\n",
    "        'Author': 'str',       # 'Author' should be a string\n",
    "        'Rating': 'int',       # 'Rating' should be an integer\n",
    "        'Text': 'str',         # 'Text' should be a string\n",
    "        'Time': 'int',         # 'Time' should be an integer\n",
    "        'Date': 'str',         # 'Date' should be initially a string for conversion\n",
    "        'Response': 'str'      # 'Response' should be a string\n",
    "    }\n",
    "    \n",
    "    # Convert the columns to the specified data types\n",
    "    df = df.astype(col_dict)  \n",
    "    \n",
    "    # Ensure the 'Text' column is a string, and fill NaN values with an empty string\n",
    "    df[\"Text\"] = df[\"Text\"].astype(str).fillna(\"\")  # Replace NaN values in 'Text' with an empty string\n",
    "\n",
    "    # Convert the 'Date' column to datetime format, handling errors as 'coerce' (invalid dates will be converted to NaT)\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "    \n",
    "    # Return the DataFrame with converted data types\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a25419-dc73-4dc9-951b-13a4c0a2f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the data_types function to the reviews DataFrame\n",
    "reviews_df = data_types(reviews_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8a8b62-6d84-47cb-99ce-7923cf0c7e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the new data types of the columns\n",
    "reviews_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bb3f2d-e818-45a4-a93f-96557fe1ed6d",
   "metadata": {},
   "source": [
    "<h3>4.2 Text Length and Word Count Analysis</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df075383-c06d-40d8-bb0e-dd2cfc07cc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column 'Review Length' that contains the number of characters in each review text\n",
    "reviews_df[\"Review Length\"] = reviews_df[\"Text\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebba533-6bbb-42bd-8ce9-427f1d9688af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column 'Word Count' that contains the number of words in each review text\n",
    "reviews_df[\"Word Count\"] = reviews_df[\"Text\"].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecf76b8-3ce6-41ea-967d-218c472dd3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b074c25-49f9-45c8-9621-9299c15c07b0",
   "metadata": {},
   "source": [
    "<h3>4.3 Handling Duplicate Reviews</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e0ec4e-3e68-427c-a050-e64e778abc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and extract rows with duplicate Review IDs\n",
    "duplicate_review_ids = reviews_df[reviews_df.duplicated(subset=\"Review ID\", keep=False)]\n",
    "\n",
    "# Count the number of duplicate Review IDs\n",
    "num_duplicate_review_ids = duplicate_review_ids.shape[0]\n",
    "print(f\"Number of duplicate Review IDs: {num_duplicate_review_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e8a439-cfae-4482-ae6b-00d528a1cce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and extract rows with duplicate combinations of Place ID, Author, and Text\n",
    "duplicate_combinations = reviews_df[reviews_df.duplicated(subset=[\"Place ID\", \"Author\", \"Text\"], keep=False)]\n",
    "\n",
    "# Count the number of duplicate combinations of Place ID, Author, and Text\n",
    "num_duplicate_combinations = duplicate_combinations.shape[0]\n",
    "print(f\"Number of duplicates for the combination of Place ID, Author, and Text: {num_duplicate_combinations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3465cfee-7810-4eb1-ac93-56f94c1966d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates based on Review ID, keeping the first occurrence\n",
    "reviews_df = reviews_df.drop_duplicates(subset=\"Review ID\", keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375375a9-eb35-4217-a6f5-23ca80e08236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates based on the combination of Place ID, Author, and Text, keeping the first occurrence\n",
    "reviews_df = reviews_df.drop_duplicates(subset=[\"Place ID\", \"Author\", \"Text\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e130e7-7215-46bb-8643-3ac768143dee",
   "metadata": {},
   "source": [
    "<h3>4.4 Handling Missing Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745c97db-45de-41c5-af0c-34fa13822504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of missing values in each column\n",
    "reviews_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe8c71a-04fd-46ba-ae08-6dcbf61a2184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where the 'Response' column has missing values\n",
    "reviews_df.dropna(subset=\"Response\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740e72e3-399a-4b2f-bac0-678d4fb2674c",
   "metadata": {},
   "source": [
    "<h3>4.5 Reorganizing DataFrame Columns</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9822632-4332-44b1-9364-07dbd7492be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns of the DataFrame to follow a specific sequence\n",
    "ordered_columns = [\"Place ID\", \"Place Name\", \"Review ID\", \"Author\", \"Rating\", \"Text\", \"Review Length\", \"Word Count\", \"Time\", \n",
    "                   \"Date\", \"Response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bcb2d4-d64f-41be-9719-4a8a65ddd26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the new column order to the DataFrame\n",
    "reviews_df = reviews_df[ordered_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe4fec9-eea9-401d-8a83-aee4f013ed16",
   "metadata": {},
   "source": [
    "<h2>5. Export Processed Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca6e75-9975-473b-bcaf-b77c7331f906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to a CSV file\n",
    "reviews_df.to_csv(os.path.join(os.path.abspath(\"..\"), \"data/processed/reviews_processed.csv\"), sep=\";\", index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
